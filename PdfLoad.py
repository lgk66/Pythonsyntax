# java_interview_rag.py
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

# 1. åŠ è½½PDFï¼ˆç”¨ç»å¯¹è·¯å¾„ï¼ï¼‰
loader = PyPDFLoader(r"D:\å…¨éƒ¨æ–‡ä»¶\èµ„æ–™\é¢è¯•é¢˜\ï¼ˆå¤‡ä»½ï¼‰æœ€æ–°é¢è¯•æ€»ç»“3.29.pdf")
docs = loader.load()

# 2. æ™ºèƒ½åˆ†å—ï¼ˆä¿ç•™é¢˜ç›®-ç­”æ¡ˆç»“æ„ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=60,
    # ç‰¹åˆ«å¤„ç†â€œé—®ï¼šxxxï¼Ÿç­”ï¼šxxxâ€çš„æ ¼å¼
    separators=["\n\n", "ã€‚", "ï¼Ÿ", "\n", "é—®ï¼š", "ç­”ï¼š", "1.", "2.", "3."]
)
splits = text_splitter.split_documents(docs)

# 3. å­˜å…¥å‘é‡åº“
embeddings = OllamaEmbeddings(model="nomic-embed-text", base_url="http://127.0.0.1:11434")

# å°è¯•å¤šç§å‘é‡å­˜å‚¨æ–¹æ¡ˆ
vectorstore = None

# æ–¹æ¡ˆ1ï¼šå°è¯•FAISS
try:
    from langchain_community.vectorstores import FAISS
    vectorstore = FAISS.from_documents(splits, embeddings)
    vectorstore.save_local("./java_vector_db")
    print("âœ… æˆåŠŸä½¿ç”¨FAISSå‘é‡æ•°æ®åº“")
except Exception as e:
    print(f"âš ï¸ FAISSä¸å¯ç”¨: {e}")
    
# æ–¹æ¡ˆ2ï¼šå°è¯•DocArray
if vectorstore is None:
    try:
        from langchain_community.vectorstores import DocArrayInMemorySearch
        vectorstore = DocArrayInMemorySearch.from_documents(splits, embeddings)
        print("âœ… æˆåŠŸä½¿ç”¨DocArrayå†…å­˜å­˜å‚¨")
    except Exception as e:
        print(f"âš ï¸ DocArrayä¸å¯ç”¨: {e}")

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨æœ€åŸºç¡€çš„å†…å­˜å­˜å‚¨ï¼ˆæ€»æ˜¯å¯ç”¨ï¼‰
if vectorstore is None:
    try:
        from langchain_community.vectorstores import InMemoryVectorStore
        vectorstore = InMemoryVectorStore.from_documents(splits, embeddings)
        print("âœ… æˆåŠŸä½¿ç”¨åŸºç¡€å†…å­˜å‘é‡å­˜å‚¨")
    except Exception as e:
        print(f"âš ï¸ åŸºç¡€å†…å­˜å­˜å‚¨ä¹Ÿä¸å¯ç”¨: {e}")
        # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šæ‰‹åŠ¨å®ç°ç®€å•çš„å‘é‡å­˜å‚¨
        print("ğŸ”„ ä½¿ç”¨ç®€æ˜“å‘é‡å­˜å‚¨å®ç°...")
        from langchain_core.documents import Document
        import numpy as np
        from sklearn.metrics.pairwise import cosine_similarity
        
        class SimpleVectorStore:
            def __init__(self):
                self.documents = []
                self.embeddings = []
                
            def add_documents(self, docs):
                for doc in docs:
                    # è·å–æ–‡æ¡£åµŒå…¥
                    emb = embeddings.embed_query(doc.page_content)
                    self.documents.append(doc)
                    self.embeddings.append(emb)
                
            def similarity_search(self, query, k=4):
                if not self.embeddings:
                    return []
                
                # è·å–æŸ¥è¯¢åµŒå…¥
                query_emb = embeddings.embed_query(query)
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarities = cosine_similarity([query_emb], self.embeddings)[0]
                
                # è·å–æœ€ç›¸ä¼¼çš„æ–‡æ¡£ç´¢å¼•
                top_indices = np.argsort(similarities)[-k:][::-1]
                
                # è¿”å›ç»“æœ
                results = []
                for idx in top_indices:
                    if similarities[idx] > 0.1:  # è®¾ç½®æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
                        results.append(self.documents[idx])
                
                return results[:k]
            
            def as_retriever(self):
                return SimpleRetriever(self)
        
        class SimpleRetriever:
            def __init__(self, vectorstore):
                self.vectorstore = vectorstore
            
            def get_relevant_documents(self, query):
                return self.vectorstore.similarity_search(query)
        
        vectorstore = SimpleVectorStore()
        vectorstore.add_documents(splits)
        print("âœ… æˆåŠŸä½¿ç”¨ç®€æ˜“å‘é‡å­˜å‚¨")

# 5. RAGé“¾
llm = OllamaLLM(model="qwen:4b", base_url="http://127.0.0.1:11434", temperature=0.1)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    return_source_documents=True
)

# 6. æµ‹è¯•é—®é¢˜
questions = [
    "JavaåŸºæœ¬æ•°æ®ç±»å‹ï¼Ÿ",
    "æ¥å£å’ŒæŠ½è±¡ç±»çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    "æ–¹æ³•çš„é‡è½½å’Œé‡å†™"
]

for q in questions:
    result = qa_chain.invoke(q)
    print(f"\nã€é—®é¢˜ã€‘{q}")
    print(f"ã€ç­”æ¡ˆã€‘{result['result']}")
    print(f"ã€æ¥æºã€‘{[doc.metadata['source'] for doc in result['source_documents']]}")